{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pydicom\n",
    "import cv2\n",
    "from math import ceil\n",
    "# import json\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from helpers import get_ddsm_table, get_INBreast_table, get_VinDR_table, mask_image, run_intensity_functions, run_glcm_features, get_master_df, process_image\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helpers import get_ddsm_table, get_INBreast_table, get_VinDR_table, get_master_df, mask_image\n",
    "from process import process_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddsm_df = get_ddsm_table(\"../../DDSM\")\n",
    "INbreast_df = get_INBreast_table(\"../../INbreast Release 1.0\")\n",
    "vindr_df = get_VinDR_table(\"../../VinDr\")\n",
    "master_df = get_master_df(vindr_df, ddsm_df, INbreast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.replace({'breast_density': {'DENSITY A': 1, 'DENSITY B': 2, 'DENSITY C': 3, 'DENSITY D': 4}}, inplace=True)\n",
    "master_df['breast_density'] = pd.to_numeric(master_df['breast_density'], errors='coerce')\n",
    "master_df.dropna(subset=['breast_density'], inplace=True)\n",
    "master_df['breast_density'] = master_df['breast_density'] - 1\n",
    "# master_df = master_df.groupby('breast_density').sample(n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(row, process):\n",
    "    image_size = (650,400)\n",
    "    dicom_path = row[\"full_path\"]\n",
    "    vendor = row[\"Manufacturer\"]\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "    image = dicom_data.pixel_array\n",
    "    image = mask_image(image)\n",
    "    \n",
    "    if process:\n",
    "        image = process_image(image, vendor) # custom processing\n",
    "\n",
    "    image = (image - np.mean(image))/np.std(image)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.expand_dims(image, axis=3)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(df, batch_size, process=False):\n",
    "    num_samples = len(df)\n",
    "    image_size = (650,400)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_df = df.iloc[offset:offset + batch_size]\n",
    "            images = []\n",
    "            labels = []\n",
    "            \n",
    "            for _, row in batch_df.iterrows():\n",
    "                dicom_path = row[\"full_path\"]\n",
    "                label = row[\"breast_density\"]\n",
    "                vendor = row[\"Manufacturer\"]\n",
    "                dicom_data = pydicom.dcmread(dicom_path)\n",
    "                image = dicom_data.pixel_array\n",
    "                image = mask_image(image)\n",
    "                \n",
    "                if process:\n",
    "                    image = process_image(image, vendor) # custom processing\n",
    "\n",
    "                image = (image - np.mean(image))/np.std(image)\n",
    "                image = cv2.resize(image, image_size)\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            images = np.array(images).reshape(-1, 1, *image_size)  # Add channel dimension\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            images = torch.tensor(images, dtype=torch.float32).to('cuda')\n",
    "            labels = torch.tensor(labels, dtype=torch.long).to('cuda')\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only uncomment if data balancing should be done\n",
    "\n",
    "# ros = RandomOverSampler()\n",
    "# x, y = ros.fit_resample(master_df.drop(columns=['breast_density']), master_df['breast_density'])\n",
    "# x['breast_density'] = y\n",
    "# master_df = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> This part runs with model.py (our custom model) </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 33 33\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_df, temp_df = train_test_split(master_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "\n",
    "# Create generators\n",
    "train_gen = data_generator(train_df, batch_size, True)\n",
    "val_gen = data_generator(val_df, batch_size, True)\n",
    "test_gen = data_generator(test_df, batch_size, True)\n",
    "\n",
    "# # Get the number of steps per epoch\n",
    "train_steps = ceil(len(train_df) // batch_size)\n",
    "val_steps = ceil(len(val_df) // batch_size)\n",
    "test_steps = ceil(len(test_df) // batch_size)\n",
    "print(train_steps, val_steps, test_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_steps, val_steps, epochs, batch_size):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_f1_scores = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_f1_scores = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    patience = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_acc, train_f1 = 0, 0, 0\n",
    "        for _ in tqdm(range(train_steps), desc='Training batch'):\n",
    "            images, labels = next(train_gen)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (preds == labels).sum().item()\n",
    "            train_f1 += f1_score(labels.cpu(), preds.cpu(), average='weighted')\n",
    "\n",
    "        train_loss /= train_steps\n",
    "        train_acc /= (train_steps*batch_size)\n",
    "        train_f1 /= train_steps\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_f1_scores.append(train_f1)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc, val_f1 = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for _ in tqdm(range(val_steps), desc='Validation batch'):\n",
    "                images, labels = next(val_gen)         \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Calculate metrics\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += (preds == labels).sum().item()\n",
    "                val_f1 += f1_score(labels.cpu(), preds.cpu(), average='weighted')\n",
    "\n",
    "        val_loss /= val_steps\n",
    "        val_acc /= (val_steps*batch_size)\n",
    "        val_f1 /= val_steps\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_f1_scores.append(val_f1)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.4f} | Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    return (train_losses, train_accuracies, train_f1_scores, val_losses, val_accuracies, val_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BaselineBreastModel as CNNModel\n",
    "model = CNNModel(device='cuda', nodropout_probability=1, gaussian_noise_std=0)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineBreastModel(\n",
       "  (_conv_layer_ls): ModuleList(\n",
       "    (0): SimpleConvLayer(\n",
       "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (1): SimpleConvLayer(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (2-3): 2 x SimpleConvLayer(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (4): SimpleConvLayer(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (5-9): 5 x SimpleConvLayer(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (10): SimpleConvLayer(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (11-12): 2 x SimpleConvLayer(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (all_views_pad): SimplePad()\n",
       "  (all_views_max_pool): SimpleMaxPool()\n",
       "  (all_views_avg_pool): SimpleAvgPool()\n",
       "  (fc1): Linear(in_features=19584, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (gaussian_noise_layer): SimpleGaussianNoise()\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights_he_uniform(layer):\n",
    "    if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "        init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "model.apply(initialize_weights_he_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 158/158 [20:25<00:00,  7.76s/it]\n",
      "Validation batch: 100%|██████████| 33/33 [04:13<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.4907 | Train Acc: 0.2530 | Train F1: 0.1075\n",
      "Validation Loss: 1.4956 | Validation Acc: 0.2481 | Validation F1: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch:   6%|▋         | 10/158 [01:10<17:24,  7.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, train_steps, val_steps, epochs, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m train_loss, train_acc, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(train_steps), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining batch\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mdata_generator\u001b[1;34m(df, batch_size, process)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[0;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m process_image(image, vendor) \u001b[38;5;66;03m# custom processing\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m (image \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mstd(image)\n\u001b[0;32m     23\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, image_size)\n\u001b[0;32m     24\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3593\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3597\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_core\\_methods.py:127\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    124\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    125\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = train_model(model, optimizer=optim.Adam(model.parameters(), lr=0.0001), \n",
    "                      train_steps=train_steps, val_steps=val_steps, \n",
    "                      epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "torch.save(model, 'model_full.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Runs with the prebuilt model from the GitHub Repo </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_torch as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineBreastModel('cuda', nodropout_probability=1.0, gaussian_noise_std=0.0).to('cuda')\n",
    "model.load_state_dict(torch.load('model.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = master_df[master_df['Manufacturer'].isin(['SIEMENS', 'Planmed', 'IMS s.r.l.', 'IMS GIOTTO S.p.A.'])]\n",
    "df.sort_values('full_path', inplace=True)\n",
    "df['patient'] = df['full_path'].str.split('\\\\').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = df['patient'].unique()\n",
    "goodpatients = []\n",
    "for i in patients:\n",
    "    rows = df[df['patient'] == i]\n",
    "    views = rows['view_position'].values\n",
    "    lats = rows['laterality'].values\n",
    "    densities = rows['breast_density'].nunique()\n",
    "    if('CC' in views and 'MLO' in views):\n",
    "        if('L' in lats and 'R' in lats):\n",
    "            if(len(views) == 4 and len(lats) == 4):\n",
    "                if(densities == 1):\n",
    "                    goodpatients.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['patient'].isin(goodpatients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [06:05<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# for i in tqdm(range(0, len(df), 4)):\n",
    "#     l_cc = None\n",
    "#     r_cc = None\n",
    "#     l_mlo = None\n",
    "#     r_mlo = None\n",
    "#     for j in range(4):\n",
    "#         row = df.iloc[i+j]\n",
    "#         image = load_image(row, False)\n",
    "#         if(row['laterality'] == 'L' and row['view_position'] == 'CC'):\n",
    "#             l_cc = image\n",
    "#         elif(row['laterality'] == 'R' and row['view_position'] == 'CC'):\n",
    "#             r_cc = image\n",
    "#         elif(row['laterality'] == 'L' and row['view_position'] == 'MLO'):\n",
    "#             l_mlo = image\n",
    "#         elif(row['laterality'] == 'R' and row['view_position'] == 'MLO'):\n",
    "#             r_mlo = image\n",
    "#     x = {\n",
    "#         \"L-CC\": torch.Tensor(l_cc).permute(0, 3, 1, 2).to(device),\n",
    "#         \"L-MLO\": torch.Tensor(l_mlo).permute(0, 3, 1, 2).to(device),\n",
    "#         \"R-CC\": torch.Tensor(r_cc).permute(0, 3, 1, 2).to(device),\n",
    "#         \"R-MLO\": torch.Tensor(r_mlo).permute(0, 3, 1, 2).to(device),\n",
    "#     }\n",
    "#     label = row['breast_density']\n",
    "#     with torch.no_grad():\n",
    "#         prediction_density = model(x).cpu()\n",
    "#         pred = torch.argmax(prediction_density, dim=1)\n",
    "#         preds.append(pred.item())\n",
    "#         labels.append(int(label))\n",
    "#         acc = (pred.item() == int(label))\n",
    "#         if(acc):\n",
    "#             correct+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_gen(df, process):\n",
    "    num_samples = len(df)\n",
    "    while True:\n",
    "        for i in range(0, num_samples, 4):\n",
    "            l_cc = None\n",
    "            r_cc = None\n",
    "            l_mlo = None\n",
    "            r_mlo = None\n",
    "            for j in range(4):\n",
    "                row = df.iloc[i+j]\n",
    "                image = load_image(row, process)\n",
    "                if(row['laterality'] == 'L' and row['view_position'] == 'CC'):\n",
    "                    l_cc = image\n",
    "                elif(row['laterality'] == 'R' and row['view_position'] == 'CC'):\n",
    "                    r_cc = image\n",
    "                elif(row['laterality'] == 'L' and row['view_position'] == 'MLO'):\n",
    "                    l_mlo = image\n",
    "                elif(row['laterality'] == 'R' and row['view_position'] == 'MLO'):\n",
    "                    r_mlo = image\n",
    "                label = row['breast_density']\n",
    "            x = {\n",
    "                \"L-CC\": torch.Tensor(l_cc).permute(0, 3, 1, 2).to(device),\n",
    "                \"L-MLO\": torch.Tensor(l_mlo).permute(0, 3, 1, 2).to(device),\n",
    "                \"R-CC\": torch.Tensor(r_cc).permute(0, 3, 1, 2).to(device),\n",
    "                \"R-MLO\": torch.Tensor(r_mlo).permute(0, 3, 1, 2).to(device),\n",
    "            }\n",
    "            label = torch.tensor(int(label), dtype=torch.long).view(1).to(device)\n",
    "            yield x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = df[\"patient\"].unique()\n",
    "\n",
    "train_ids, temp_ids = train_test_split(patient_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = df[df[\"patient\"].isin(train_ids)]\n",
    "val_data = df[df[\"patient\"].isin(val_ids)]\n",
    "test_data = df[df[\"patient\"].isin(test_ids)]\n",
    "\n",
    "train_gen = new_gen(train_data, True)\n",
    "val_gen = new_gen(val_data, True)\n",
    "test_gen = new_gen(test_data, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.fc2.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "train_steps, val_steps = int(len(train_data)/4), int(len(val_data)/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 335/335 [04:50<00:00,  1.15it/s]\n",
      "Validation batch: 100%|██████████| 72/72 [00:58<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.9665 | Train Acc: 0.7791 | Train F1: 0.7791\n",
      "Validation Loss: 1.0353 | Validation Acc: 0.7083 | Validation F1: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 335/335 [04:53<00:00,  1.14it/s]\n",
      "Validation batch: 100%|██████████| 72/72 [00:59<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 0.9646 | Train Acc: 0.7791 | Train F1: 0.7791\n",
      "Validation Loss: 1.0353 | Validation Acc: 0.7083 | Validation F1: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 335/335 [04:55<00:00,  1.13it/s]\n",
      "Validation batch: 100%|██████████| 72/72 [00:59<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 0.9647 | Train Acc: 0.7791 | Train F1: 0.7791\n",
      "Validation Loss: 1.0353 | Validation Acc: 0.7083 | Validation F1: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 335/335 [05:03<00:00,  1.10it/s]\n",
      "Validation batch: 100%|██████████| 72/72 [01:04<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.9646 | Train Acc: 0.7791 | Train F1: 0.7791\n",
      "Validation Loss: 1.0353 | Validation Acc: 0.7083 | Validation F1: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 335/335 [05:15<00:00,  1.06it/s]\n",
      "Validation batch: 100%|██████████| 72/72 [01:05<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.9646 | Train Acc: 0.7791 | Train F1: 0.7791\n",
      "Validation Loss: 1.0353 | Validation Acc: 0.7083 | Validation F1: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = train_model(model, optimizer, train_steps, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = len(test_data)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast_density\n",
       "2.0    1044\n",
       "3.0     168\n",
       "1.0     120\n",
       "0.0       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['breast_density'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: 100%|██████████| 72/72 [01:02<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "preds = []\n",
    "truths = []\n",
    "for _ in tqdm(range(int(test_steps)), desc='Training batch'):\n",
    "    images, labels = next(test_gen)\n",
    "    with torch.no_grad():\n",
    "        prediction_density = model(images)\n",
    "        pred = torch.argmax(prediction_density, dim=1)\n",
    "        preds.append(pred.item())\n",
    "        truths.append(int(labels))\n",
    "        acc = (pred.item() == int(labels))\n",
    "        if(acc):\n",
    "            correct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.38888888888889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/72 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(truths, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(truths), yticklabels=np.unique(truths))\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616360454943133"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(truths, preds, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
